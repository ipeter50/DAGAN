{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "import random as random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = 10\n",
    "cuda = torch.cuda.is_available()\n",
    "device = \"cuda:0\" if cuda else \"cpu\"\n",
    "\n",
    "def onehot(k):\n",
    "    \"\"\"\n",
    "    Converts a number to its one-hot or 1-of-k representation\n",
    "    vector.\n",
    "    :param k: (int) length of vector\n",
    "    :return: onehot function\n",
    "    \"\"\"\n",
    "    def encode(label):\n",
    "        y = torch.zeros(k)\n",
    "        if label < k:\n",
    "            y[label] = 1\n",
    "        return y\n",
    "    return encode\n",
    "\n",
    "def get_mnist(location=\"./\", batch_size=128):\n",
    "    from functools import reduce\n",
    "    from operator import __or__\n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "    from torchvision.datasets import MNIST\n",
    "    import torchvision.transforms as transforms\n",
    "    \n",
    "    compose = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "        ])\n",
    "    \n",
    "    img_transform = lambda x: compose(x).view(-1)\n",
    "    \n",
    "\n",
    "    mnist_train = MNIST(location, train=True, download=True,transform=img_transform)\n",
    "    mnist_valid = MNIST(location, train=False, download=True,transform=img_transform)\n",
    "\n",
    "    # Dataloaders for MNIST\n",
    "    labelled = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size)\n",
    "    \n",
    "    validation = torch.utils.data.DataLoader(mnist_valid, batch_size=batch_size)\n",
    "\n",
    "    return labelled, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled, valid = get_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, in_dim=784):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(in_features=in_dim, out_features=256),\n",
    "                                 nn.ReLU(),\n",
    "#                                  nn.Dropout(0.3),\n",
    "                                 nn.Linear(in_features=256, out_features=256),\n",
    "                                 nn.ReLU(),\n",
    "#                                  nn.Dropout(0.3),\n",
    "                                 nn.Linear(in_features=256, out_features=256),\n",
    "                                 nn.ReLU(),\n",
    "#                                  nn.Dropout(0.3),\n",
    "                                 nn.Linear(in_features=256, out_features=10),\n",
    "                                 nn.LogSoftmax(dim=-1))\n",
    "        \n",
    "    def forward(self,x):        \n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Classifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerC = torch.optim.Adam(classifier.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCE = nn.BCELoss()\n",
    "NLL = nn.NLLLoss()\n",
    "\n",
    "MSE = nn.MSELoss()\n",
    "NUM_EPOCH = 100\n",
    "\n",
    "def train():\n",
    "    loss_c = []\n",
    "    for epoch in range(NUM_EPOCH):\n",
    "        for idx, batch_data in enumerate(labelled):\n",
    "            batch_size = batch_data[0].shape[0]            \n",
    "            \n",
    "            # retrieve real data from loader\n",
    "            real_images =batch_data[0].cuda()\n",
    "            classes_real = batch_data[1].cuda()\n",
    "            \n",
    "            # Train classifier on fake and real data\n",
    "            prediction_real = classifier(real_images)\n",
    "            \n",
    "            \n",
    "            \n",
    "#             lossC = MSE(prediction_real, classes_real)\n",
    "            lossC = NLL(prediction_real, classes_real)\n",
    "            \n",
    "            lossC.backward()\n",
    "            \n",
    "            optimizerC.step()           \n",
    "            loss_c.append(lossC.item())\n",
    "\n",
    "        print(\"Epoch: \", epoch, \" Closs: \", np.mean(loss_c[-20:]))\n",
    "        print(\"Accuracy:\", test())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    r =0\n",
    "    length = 0 \n",
    "    for idx, batch_data in enumerate(valid):\n",
    "        batch_size = batch_data[0].shape[0]\n",
    "        real_images = batch_data[0].cuda()\n",
    "        classes_real = batch_data[1].cuda()\n",
    "#         print(classes_real.argmax(dim=-1))\n",
    "\n",
    "        predictions_real = classifier(real_images).argmax(dim=-1)\n",
    "#         print(predictions_real)\n",
    "#         r += torch.sum(abs(predictions_real-classes_real)).item()\n",
    "        r += predictions_real.eq(classes_real).sum().item()\n",
    "        length += batch_size\n",
    "    return r/length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  Closs:  1.127143558859825\n",
      "Accuracy: 0.6754\n",
      "Epoch:  1  Closs:  1.2023566335439682\n",
      "Accuracy: 0.5879\n",
      "Epoch:  2  Closs:  0.7634003609418869\n",
      "Accuracy: 0.7385\n",
      "Epoch:  3  Closs:  0.4577137365937233\n",
      "Accuracy: 0.831\n",
      "Epoch:  4  Closs:  0.482887626439333\n",
      "Accuracy: 0.8238\n",
      "Epoch:  5  Closs:  0.48293308094143866\n",
      "Accuracy: 0.8006\n",
      "Epoch:  6  Closs:  0.4049548789858818\n",
      "Accuracy: 0.8297\n",
      "Epoch:  7  Closs:  0.38354877270758153\n",
      "Accuracy: 0.8445\n",
      "Epoch:  8  Closs:  0.3232653960585594\n",
      "Accuracy: 0.8564\n",
      "Epoch:  9  Closs:  0.29146419167518617\n",
      "Accuracy: 0.8825\n",
      "Epoch:  10  Closs:  0.2869791928678751\n",
      "Accuracy: 0.8821\n",
      "Epoch:  11  Closs:  0.3081853505223989\n",
      "Accuracy: 0.8779\n",
      "Epoch:  12  Closs:  0.28983214870095253\n",
      "Accuracy: 0.8848\n",
      "Epoch:  13  Closs:  0.2339403409510851\n",
      "Accuracy: 0.9062\n",
      "Epoch:  14  Closs:  0.23218420408666135\n",
      "Accuracy: 0.9098\n",
      "Epoch:  15  Closs:  0.19537619296461345\n",
      "Accuracy: 0.9183\n",
      "Epoch:  16  Closs:  0.20013975352048874\n",
      "Accuracy: 0.9211\n",
      "Epoch:  17  Closs:  0.20421941792592407\n",
      "Accuracy: 0.9148\n",
      "Epoch:  18  Closs:  0.16734905615448953\n",
      "Accuracy: 0.9256\n",
      "Epoch:  19  Closs:  0.16534878332167863\n",
      "Accuracy: 0.9326\n",
      "Epoch:  20  Closs:  0.1658498352393508\n",
      "Accuracy: 0.9285\n",
      "Epoch:  21  Closs:  0.1494027568027377\n",
      "Accuracy: 0.9324\n",
      "Epoch:  22  Closs:  0.15452468656003476\n",
      "Accuracy: 0.937\n",
      "Epoch:  23  Closs:  0.13932407982647418\n",
      "Accuracy: 0.9395\n",
      "Epoch:  24  Closs:  0.12991126235574485\n",
      "Accuracy: 0.9438\n",
      "Epoch:  25  Closs:  0.130672081746161\n",
      "Accuracy: 0.9433\n",
      "Epoch:  26  Closs:  0.11559959519654513\n",
      "Accuracy: 0.9467\n",
      "Epoch:  27  Closs:  0.1243156086653471\n",
      "Accuracy: 0.9452\n",
      "Epoch:  28  Closs:  0.1296839103102684\n",
      "Accuracy: 0.9447\n",
      "Epoch:  29  Closs:  0.11887657232582569\n",
      "Accuracy: 0.9473\n",
      "Epoch:  30  Closs:  0.11076925583183765\n",
      "Accuracy: 0.9468\n",
      "Epoch:  31  Closs:  0.11245819739997387\n",
      "Accuracy: 0.9504\n",
      "Epoch:  32  Closs:  0.11376380901783704\n",
      "Accuracy: 0.95\n",
      "Epoch:  33  Closs:  0.10187411522492766\n",
      "Accuracy: 0.9505\n",
      "Epoch:  34  Closs:  0.10199645897373558\n",
      "Accuracy: 0.9523\n",
      "Epoch:  35  Closs:  0.10363789619877935\n",
      "Accuracy: 0.9527\n",
      "Epoch:  36  Closs:  0.0959127095527947\n",
      "Accuracy: 0.9553\n",
      "Epoch:  37  Closs:  0.09725457252934575\n",
      "Accuracy: 0.9548\n",
      "Epoch:  38  Closs:  0.09726860420778394\n",
      "Accuracy: 0.9535\n",
      "Epoch:  39  Closs:  0.09613349130377173\n",
      "Accuracy: 0.9561\n",
      "Epoch:  40  Closs:  0.09321699747815729\n",
      "Accuracy: 0.9555\n",
      "Epoch:  41  Closs:  0.09274445753544569\n",
      "Accuracy: 0.9564\n",
      "Epoch:  42  Closs:  0.09129667989909648\n",
      "Accuracy: 0.9587\n",
      "Epoch:  43  Closs:  0.08398125292733312\n",
      "Accuracy: 0.9583\n",
      "Epoch:  44  Closs:  0.08514882763847709\n",
      "Accuracy: 0.9594\n",
      "Epoch:  45  Closs:  0.0868408746086061\n",
      "Accuracy: 0.9565\n",
      "Epoch:  46  Closs:  0.08062824504449964\n",
      "Accuracy: 0.9605\n",
      "Epoch:  47  Closs:  0.07801628382876516\n",
      "Accuracy: 0.958\n",
      "Epoch:  48  Closs:  0.07443267405033112\n",
      "Accuracy: 0.9584\n",
      "Epoch:  49  Closs:  0.07461462547071278\n",
      "Accuracy: 0.9577\n",
      "Epoch:  50  Closs:  0.06645656125620007\n",
      "Accuracy: 0.9582\n",
      "Epoch:  51  Closs:  0.07511578630656005\n",
      "Accuracy: 0.9576\n",
      "Epoch:  52  Closs:  0.0603731419891119\n",
      "Accuracy: 0.9585\n",
      "Epoch:  53  Closs:  0.05632925764657557\n",
      "Accuracy: 0.9595\n",
      "Epoch:  54  Closs:  0.06220371052622795\n",
      "Accuracy: 0.9599\n",
      "Epoch:  55  Closs:  0.062238354980945584\n",
      "Accuracy: 0.9581\n",
      "Epoch:  56  Closs:  0.05392858218401671\n",
      "Accuracy: 0.9593\n",
      "Epoch:  57  Closs:  0.051699266163632275\n",
      "Accuracy: 0.9598\n",
      "Epoch:  58  Closs:  0.048022128036245705\n",
      "Accuracy: 0.9575\n",
      "Epoch:  59  Closs:  0.052656290028244256\n",
      "Accuracy: 0.9591\n",
      "Epoch:  60  Closs:  0.04308862211182714\n",
      "Accuracy: 0.9591\n",
      "Epoch:  61  Closs:  0.04866619715467095\n",
      "Accuracy: 0.9601\n",
      "Epoch:  62  Closs:  0.03748859446495771\n",
      "Accuracy: 0.9607\n",
      "Epoch:  63  Closs:  0.03963324166834355\n",
      "Accuracy: 0.9602\n",
      "Epoch:  64  Closs:  0.03603809177875519\n",
      "Accuracy: 0.9603\n",
      "Epoch:  65  Closs:  0.03777517359703779\n",
      "Accuracy: 0.9596\n",
      "Epoch:  66  Closs:  0.03804912185296416\n",
      "Accuracy: 0.9597\n",
      "Epoch:  67  Closs:  0.03295163037255407\n",
      "Accuracy: 0.9603\n",
      "Epoch:  68  Closs:  0.03136045979335904\n",
      "Accuracy: 0.9616\n",
      "Epoch:  69  Closs:  0.037666657380759715\n",
      "Accuracy: 0.96\n",
      "Epoch:  70  Closs:  0.030203530844300986\n",
      "Accuracy: 0.9605\n",
      "Epoch:  71  Closs:  0.03398511931300163\n",
      "Accuracy: 0.9605\n",
      "Epoch:  72  Closs:  0.030973678827285765\n",
      "Accuracy: 0.9584\n",
      "Epoch:  73  Closs:  0.03201673487201333\n",
      "Accuracy: 0.9585\n",
      "Epoch:  74  Closs:  0.031241407431662083\n",
      "Accuracy: 0.9612\n",
      "Epoch:  75  Closs:  0.03634947594255209\n",
      "Accuracy: 0.9606\n",
      "Epoch:  76  Closs:  0.03333561504259706\n",
      "Accuracy: 0.9604\n",
      "Epoch:  77  Closs:  0.02868446446955204\n",
      "Accuracy: 0.9592\n",
      "Epoch:  78  Closs:  0.029682444501668216\n",
      "Accuracy: 0.9609\n",
      "Epoch:  79  Closs:  0.0357979386113584\n",
      "Accuracy: 0.9594\n",
      "Epoch:  80  Closs:  0.02630238439887762\n",
      "Accuracy: 0.9604\n",
      "Epoch:  81  Closs:  0.03659938909113407\n",
      "Accuracy: 0.9608\n",
      "Epoch:  82  Closs:  0.02902512000873685\n",
      "Accuracy: 0.9614\n",
      "Epoch:  83  Closs:  0.027683299407362937\n",
      "Accuracy: 0.9576\n",
      "Epoch:  84  Closs:  0.024979022948537023\n",
      "Accuracy: 0.9616\n",
      "Epoch:  85  Closs:  0.023759222775697707\n",
      "Accuracy: 0.9612\n",
      "Epoch:  86  Closs:  0.0211462264880538\n",
      "Accuracy: 0.9612\n",
      "Epoch:  87  Closs:  0.02355003161355853\n",
      "Accuracy: 0.9593\n",
      "Epoch:  88  Closs:  0.02161350306123495\n",
      "Accuracy: 0.9603\n",
      "Epoch:  89  Closs:  0.01789782140403986\n",
      "Accuracy: 0.9613\n",
      "Epoch:  90  Closs:  0.020297573460265995\n",
      "Accuracy: 0.9621\n",
      "Epoch:  91  Closs:  0.015218779724091292\n",
      "Accuracy: 0.9602\n",
      "Epoch:  92  Closs:  0.023454276344273238\n",
      "Accuracy: 0.9592\n",
      "Epoch:  93  Closs:  0.027474477887153625\n",
      "Accuracy: 0.9592\n",
      "Epoch:  94  Closs:  0.018104918859899045\n",
      "Accuracy: 0.9594\n",
      "Epoch:  95  Closs:  0.02008248406345956\n",
      "Accuracy: 0.9582\n",
      "Epoch:  96  Closs:  0.014283491671085358\n",
      "Accuracy: 0.9612\n",
      "Epoch:  97  Closs:  0.010802822187542915\n",
      "Accuracy: 0.9612\n",
      "Epoch:  98  Closs:  0.007659544609487057\n",
      "Accuracy: 0.9592\n",
      "Epoch:  99  Closs:  0.012573800113750621\n",
      "Accuracy: 0.9607\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
